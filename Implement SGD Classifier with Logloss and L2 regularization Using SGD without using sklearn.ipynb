{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7eiDWcM_MC3H"
   },
   "source": [
    "# <font color='red'>Implement SGD Classifier with Logloss and L2 regularization Using SGD without using sklearn</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yfe2NTQtLq11"
   },
   "source": [
    "**There will be some functions that start with the word \"grader\" ex: grader_weights(), grader_sigmoid(), grader_logloss() etc, you should not change those function definition.<br><br>Every Grader function has to return True.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Fk5DSPCLxqT-"
   },
   "source": [
    "<font color='red'> Importing packages</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "42Et8BKIxnsp"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NpSk3WQBx7TQ"
   },
   "source": [
    "<font color='red'>Creating custom dataset</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BsMp0oWzx6dv"
   },
   "outputs": [],
   "source": [
    "# please don't change random_state\n",
    "X, y = make_classification(n_samples=50000, n_features=15, n_informative=10, n_redundant=5,\n",
    "                           n_classes=2, weights=[0.7], class_sep=0.7, random_state=15)\n",
    "# make_classification is used to create custom dataset \n",
    "# Please check this link (https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_classification.html) for more details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "L8W2fg1cyGdX",
    "outputId": "029d4c84-03b2-4143-a04c-34ff49c88890"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50000, 15), (50000,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x99RWCgpqNHw"
   },
   "source": [
    "<font color='red'>Splitting data into train and test </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0Kh4dBfVyJMP"
   },
   "outputs": [],
   "source": [
    "#please don't change random state\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "0DR_YMBsyOci",
    "outputId": "732014d9-1731-4d3f-918f-a9f5255ee149"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((37500, 15), (37500,), (12500, 15), (12500,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BW4OHswfqjHR"
   },
   "source": [
    "# <font color='red' size=5>SGD classifier</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 118
    },
    "colab_type": "code",
    "id": "3HpvTwDHyQQy",
    "outputId": "5729f08c-079a-4b17-bf51-f9aeb5abb13b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "       eta0=0.0001, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='constant', loss='log', max_iter=None, n_iter=None,\n",
       "       n_jobs=1, penalty='l2', power_t=0.5, random_state=15, shuffle=True,\n",
       "       tol=0.001, verbose=2, warm_start=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# alpha : float\n",
    "# Constant that multiplies the regularization term. \n",
    "\n",
    "# eta0 : double\n",
    "# The initial learning rate for the ‘constant’, ‘invscaling’ or ‘adaptive’ schedules.\n",
    "\n",
    "clf = linear_model.SGDClassifier(eta0=0.0001, alpha=0.0001, loss='log', random_state=15, penalty='l2', tol=1e-3, verbose=2, learning_rate='constant')\n",
    "clf\n",
    "# Please check this documentation (https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 638
    },
    "colab_type": "code",
    "id": "YYaVyQ2lyXcr",
    "outputId": "dc0bf840-b37e-4552-e513-84b64f6c64c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 0.76, NNZs: 15, Bias: -0.314605, T: 37500, Avg. loss: 0.455801\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.92, NNZs: 15, Bias: -0.469578, T: 75000, Avg. loss: 0.394737\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.98, NNZs: 15, Bias: -0.580452, T: 112500, Avg. loss: 0.385561\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1.02, NNZs: 15, Bias: -0.660824, T: 150000, Avg. loss: 0.382161\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1.04, NNZs: 15, Bias: -0.717218, T: 187500, Avg. loss: 0.380474\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1.06, NNZs: 15, Bias: -0.761816, T: 225000, Avg. loss: 0.379481\n",
      "Total training time: 0.12 seconds.\n",
      "Convergence after 6 epochs took 0.12 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "       eta0=0.0001, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='constant', loss='log', max_iter=None, n_iter=None,\n",
       "       n_jobs=1, penalty='l2', power_t=0.5, random_state=15, shuffle=True,\n",
       "       tol=0.001, verbose=2, warm_start=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X=X_train, y=y_train) # fitting our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 101
    },
    "colab_type": "code",
    "id": "EAfkVI6GyaRO",
    "outputId": "bc88f920-6531-4106-9b4c-4dabb6d72b47"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.41177431,  0.18416782, -0.13895073,  0.33572511, -0.18423237,\n",
       "          0.5494352 , -0.45213692, -0.08857465,  0.21536661,  0.17351757,\n",
       "          0.18480827,  0.00443463, -0.07033001,  0.33683181,  0.02004129]]),\n",
       " (1, 15),\n",
       " array([-0.76181561]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.coef_, clf.coef_.shape, clf.intercept_\n",
    "#clf.coef_ will return the weights\n",
    "#clf.coef_.shape will return the shape of weights\n",
    "#clf.intercept_ will return the intercept term"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_-CcGTKgsMrY"
   },
   "source": [
    "\n",
    "\n",
    "```\n",
    "# This is formatted as code\n",
    "```\n",
    "\n",
    "## <font color='red' size=5> Implement Logistic Regression with L2 regularization Using SGD: without using sklearn </font>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W1_8bdzitDlM"
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "1.  We will be giving you some functions, please write code in that functions only.\n",
    "\n",
    "2.  After every function, we will be giving you expected output, please make sure that you get that output. \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zU2Y3-FQuJ3z"
   },
   "source": [
    "\n",
    "<br>\n",
    "\n",
    "* Initialize the weight_vector and intercept term to zeros (Write your code in <font color='blue'>def initialize_weights()</font>)\n",
    "\n",
    "* Create a loss function (Write your code in <font color='blue'>def logloss()</font>) \n",
    "\n",
    " $log loss = -1*\\frac{1}{n}\\Sigma_{for each Yt,Y_{pred}}(Ytlog10(Y_{pred})+(1-Yt)log10(1-Y_{pred}))$\n",
    "- for each epoch:\n",
    "\n",
    "    - for each batch of data points in train: (keep batch size=1)\n",
    "\n",
    "        - calculate the gradient of loss function w.r.t each weight in weight vector (write your code in <font color='blue'>def gradient_dw()</font>)\n",
    "\n",
    "        $dw^{(t)} = x_n(y_n − σ((w^{(t)})^{T} x_n+b^{t}))- \\frac{λ}{N}w^{(t)})$ <br>\n",
    "\n",
    "        - Calculate the gradient of the intercept (write your code in <font color='blue'> def gradient_db()</font>) <a href='https://drive.google.com/file/d/1nQ08-XY4zvOLzRX-lGf8EYB5arb7-m1H/view?usp=sharing'>check this</a>\n",
    "\n",
    "           $ db^{(t)} = y_n- σ((w^{(t)})^{T} x_n+b^{t}))$\n",
    "\n",
    "        - Update weights and intercept (check the equation number 32 in the above mentioned <a href='https://drive.google.com/file/d/1nQ08-XY4zvOLzRX-lGf8EYB5arb7-m1H/view?usp=sharing'>pdf</a>): <br>\n",
    "        $w^{(t+1)}← w^{(t)}+α(dw^{(t)}) $<br>\n",
    "\n",
    "        $b^{(t+1)}←b^{(t)}+α(db^{(t)}) $\n",
    "    - calculate the log loss for train and test with the updated weights (you can check the python assignment 10th question)\n",
    "    - And if you wish, you can compare the previous loss and the current loss, if it is not updating, then\n",
    "        you can stop the training\n",
    "    - append this loss in the list ( this will be used to see how loss is changing for each epoch after the training is over )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZR_HgjgS_wKu"
   },
   "source": [
    "<font color='blue'>Initialize weights </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GecwYV9fsKZ9"
   },
   "outputs": [],
   "source": [
    "def initialize_weights(dim):\n",
    "    ''' In this function, we will initialize our weights and bias'''\n",
    "    #initialize the weights to zeros array of (1,dim) dimensions\n",
    "    #you use zeros_like function to initialize zero, check this link https://docs.scipy.org/doc/numpy/reference/generated/numpy.zeros_like.html\n",
    "    #initialize bias to zero\n",
    "    w = np.zeros_like(dim, dtype=float)\n",
    "    b = 0\n",
    "    return w,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A7I6uWBRsKc4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w = [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "b = 0\n"
     ]
    }
   ],
   "source": [
    "dim=X_train[0] \n",
    "w,b = initialize_weights(dim)\n",
    "print('w =',(w))\n",
    "print('b =',str(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4MI5SAjP9ofN"
   },
   "source": [
    "<font color='cyan'>Grader function - 1 </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Pv1llH429wG5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim=X_train[0] \n",
    "w,b = initialize_weights(dim)\n",
    "def grader_weights(w,b):\n",
    "    assert((len(w)==len(dim)) and b==0 and np.sum(w)==0.0)\n",
    "    return True\n",
    "grader_weights(w,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QN83oMWy_5rv"
   },
   "source": [
    "<font color='blue'>Compute sigmoid </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qPv4NJuxABgs"
   },
   "source": [
    "$sigmoid(z)= 1/(1+exp(-z))$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nAfmQF47_Sd6"
   },
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    ''' In this function, we will return sigmoid of z'''\n",
    "    # compute sigmoid(z) and return\n",
    "    \n",
    "    return 1/(1+np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def grader_sigmoid(z):\n",
    "    val=sigmoid(z)\n",
    "    assert(val==0.8807970779778823)\n",
    "    return True\n",
    "grader_sigmoid(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9YrGDwg3Ae4m"
   },
   "source": [
    "<font color='cyan'>Grader function - 2</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gS7JXbcrBOFF"
   },
   "source": [
    "<font color='blue'> Compute loss </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lfEiS22zBVYy"
   },
   "source": [
    "$log loss = -1*\\frac{1}{n}\\Sigma_{for each Yt,Y_{pred}}(Ytlog10(Y_{pred})+(1-Yt)log10(1-Y_{pred}))$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VaFDgsp3sKi6"
   },
   "outputs": [],
   "source": [
    "def logloss(y_true,y_pred):\n",
    "    '''In this function, we will compute log loss '''\n",
    "    sum = 0\n",
    "    for i in range(len(y_true)):\n",
    "        sum += (y_true[i] * np.log10(y_pred[i])) + ((1 - y_true[i]) * np.log10(1 - y_pred[i]))\n",
    "    loss = -1 * (1 / len(y_true)) * sum\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Zs1BTXVSClBt"
   },
   "source": [
    "<font color='cyan'>Grader function - 3 </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LzttjvBFCuQ5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def grader_logloss(true,pred):\n",
    "    loss=logloss(true,pred)\n",
    "    assert(loss==0.07644900402910389)\n",
    "    return True\n",
    "true=[1,1,0,1,0]\n",
    "pred=[0.9,0.8,0.1,0.8,0.2]\n",
    "grader_logloss(true,pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tQabIadLCBAB"
   },
   "source": [
    "<font color='blue'>Compute gradient w.r.to  'w' </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YTMxiYKaCQgd"
   },
   "source": [
    "$dw^{(t)} = x_n(y_n − σ((w^{(t)})^{T} x_n+b^{t}))- \\frac{λ}{N}w^{(t)}$ <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NMVikyuFsKo5"
   },
   "outputs": [],
   "source": [
    "def gradient_dw(x,y,w,b,alpha,N):\n",
    "    '''In this function, we will compute the gardient w.r.to w '''\n",
    "    dw = x * (y - sigmoid(np.dot(w,x) + b) - (alpha / N) * w)\n",
    "    return dw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RUFLNqL_GER9"
   },
   "source": [
    "<font color='cyan'>Grader function - 4 </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WI3xD8ctGEnJ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def grader_dw(x,y,w,b,alpha,N):\n",
    "    grad_dw=gradient_dw(x,y,w,b,alpha,N)\n",
    "    assert(np.sum(grad_dw)==2.613689585)\n",
    "    return True\n",
    "grad_x=np.array([-2.07864835,  3.31604252, -0.79104357, -3.87045546, -1.14783286,\n",
    "       -2.81434437, -0.86771071, -0.04073287,  0.84827878,  1.99451725,\n",
    "        3.67152472,  0.01451875,  2.01062888,  0.07373904, -5.54586092])\n",
    "grad_y=0\n",
    "grad_w,grad_b=initialize_weights(grad_x)\n",
    "alpha=0.0001\n",
    "N=len(X_train)\n",
    "grader_dw(grad_x,grad_y,grad_w,grad_b,alpha,N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LE8g84_GI62n"
   },
   "source": [
    "<font color='blue'>Compute gradient w.r.to 'b' </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fHvTYZzZJJ_N"
   },
   "source": [
    "$ db^{(t)} = y_n- σ((w^{(t)})^{T} x_n+b^{t})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0nUf2ft4EZp8"
   },
   "outputs": [],
   "source": [
    "def gradient_db(x,y,w,b):\n",
    "    '''In this function, we will compute gradient w.r.to b '''\n",
    "    db = y - sigmoid(np.dot(w,x) + b)\n",
    "    return db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pbcBzufVG6qk"
   },
   "source": [
    "<font color='cyan'>Grader function - 5 </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TfFDKmscG5qZ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def grader_db(x,y,w,b):\n",
    "    grad_db=gradient_db(x,y,w,b)\n",
    "    assert(grad_db==-0.5)\n",
    "    return True\n",
    "grad_x=np.array([-2.07864835,  3.31604252, -0.79104357, -3.87045546, -1.14783286,\n",
    "       -2.81434437, -0.86771071, -0.04073287,  0.84827878,  1.99451725,\n",
    "        3.67152472,  0.01451875,  2.01062888,  0.07373904, -5.54586092])\n",
    "grad_y=0\n",
    "grad_w,grad_b=initialize_weights(grad_x)\n",
    "alpha=0.0001\n",
    "N=len(X_train)\n",
    "grader_db(grad_x,grad_y,grad_w,grad_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TCK0jY_EOvyU"
   },
   "source": [
    "<font color='blue'> Implementing logistic regression</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dmAdc5ejEZ25"
   },
   "outputs": [],
   "source": [
    "X, y = make_classification(n_samples=50000, n_features=15, n_informative=10, n_redundant=5,n_classes=2, weights=[0.7], class_sep=0.7, random_state=15)\n",
    "##Splitting train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=15)\n",
    "\n",
    "def initialize_weights(dim):\n",
    "    ''' In this function, we will initialize our weights and bias'''\n",
    "    #initialize the weights to zeros array of (dim,1) dimensions\n",
    "    #you use zeros_like function to initialize zero, check this link https://docs.scipy.org/doc/numpy/reference/generated/numpy.zeros_like.html\n",
    "    #initialize bias to zero\n",
    "    w = np.zeros_like(X_train[0])\n",
    "    b = 0\n",
    "    return w,b\n",
    "\n",
    "def sigmoid(z):\n",
    "    ''' In this function, we will return sigmoid of z'''\n",
    "    # compute sigmoid(z) and return\n",
    "    return 1/(1+np.exp(-z))\n",
    "  \n",
    "def logloss(y_true,y_pred):\n",
    "    '''In this function, we will compute log loss '''\n",
    "    sum = 0\n",
    "    for i in range(len(y_true)):\n",
    "        sum += (y_true[i] * np.log10(y_pred[i])) + ((1 - y_true[i]) * np.log10(1 - y_pred[i]))\n",
    "    loss = -1 * (1 / len(y_true)) * sum\n",
    "    return loss\n",
    "  \n",
    "def gradient_dw(x,y,w,b,alpha,N):\n",
    "    '''In this function, we will compute the gardient w.r.to w '''\n",
    "    dw = x * (y - sigmoid(np.dot(w,x) + b) - (alpha / N) * w)\n",
    "    return dw\n",
    "\n",
    "def gradient_db(x,y,w,b):\n",
    "    '''In this function, we will compute gradient w.r.to b '''\n",
    "    db = y - sigmoid(np.dot(w,x) + b)\n",
    "    return db\n",
    "\n",
    "def train(X_train,y_train,X_test,y_test,epochs,alpha,eta0):\n",
    "    \n",
    "    ''' In this function, we will implement logistic regression'''\n",
    "    #Here eta0 is learning rate\n",
    "    train_loss = []\n",
    "    test_loss = []\n",
    "    w, b = initialize_weights(X_train[0])\n",
    "    for i in range(epochs):\n",
    "        train_pred = []\n",
    "        test_pred = []\n",
    "        for j in range(N):\n",
    "            dw = gradient_dw(X_train[j],y_train[j],w,b,alpha,N)\n",
    "            db = gradient_db(X_train[j],y_train[j],w,b)\n",
    "            w = w + (eta0 * dw)\n",
    "            b = b + (eta0 * db)\n",
    "        for val in range(N):\n",
    "            train_pred.append(sigmoid(np.dot(w, X_train[val]) + b))\n",
    "            \n",
    "        loss1 = logloss(y_train, train_pred)\n",
    "        train_loss.append(loss1)\n",
    "            \n",
    "        for val in range(len(X_test)):\n",
    "            test_pred.append(sigmoid(np.dot(w, X_test[val]) + b))\n",
    "            \n",
    "        loss2 = logloss(y_test, test_pred)\n",
    "        test_loss.append(loss2)\n",
    "        \n",
    "    return w,b,train_loss,test_loss     \n",
    "\n",
    "alpha=0.0001\n",
    "eta0=0.0001\n",
    "N=len(X_train)\n",
    "epochs=10\n",
    "w,b,train_log_loss,test_log_loss=train(X_train,y_train,X_test,y_test,epochs,alpha,eta0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l4Zf_wPARlwY"
   },
   "source": [
    "<font color='red'>Goal of assignment</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l3eF_VSPSH2z"
   },
   "source": [
    "Compare your implementation and SGDClassifier's the weights and intercept, make sure they are as close as possible i.e difference should be in terms of 10^-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nx8Rs9rfEZ1R"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.01142806,  0.00680723, -0.0069383 ,  0.00240951, -0.02780871,\n",
       "          0.01584502,  0.00675934, -0.0031181 ,  0.00261994, -0.0037161 ,\n",
       "          0.01044042, -0.00217339, -0.00751739,  0.00198677,  0.00211374]]),\n",
       " array([-0.08877568]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# these are the results we got after we implemented sgd and found the optimal weights and intercept\n",
    "w-clf.coef_, b-clf.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "230YbSgNSUrQ"
   },
   "source": [
    "<font color='blue'>Plot epoch number vs train , test loss </font>\n",
    "\n",
    "* epoch number on X-axis\n",
    "* loss on Y-axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1O6GrRt7UeCJ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(*args, **kw)>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "epoch = [i for i in range(1,11,1)]\n",
    "\n",
    "plt.plot(epoch,train_log_loss , label='train_log_loss')\n",
    "plt.plot(epoch,test_log_loss, label='test_log_loss')\n",
    "plt.xlabel(\"epoch number\")\n",
    "plt.ylabel(\"log loss\")\n",
    "plt.legend()\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FUN8puFoEZtU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy :\n",
      "0.9553333333333334\n",
      "test accuracy :\n",
      "0.95288\n"
     ]
    }
   ],
   "source": [
    "def pred(w,b, X):\n",
    "    N = len(X)\n",
    "    predict = []\n",
    "    for i in range(N):\n",
    "        z=np.dot(w,X[i])+b\n",
    "        if sigmoid(z) >= 0.5: # sigmoid(w,x,b) returns 1/(1+exp(-(dot(x,w)+b)))\n",
    "            predict.append(1)\n",
    "        else:\n",
    "            predict.append(0)\n",
    "    return np.array(predict)\n",
    "print(\"train accuracy :\")\n",
    "print(1-np.sum(y_train - pred(w,b,X_train))/len(X_train))\n",
    "print(\"test accuracy :\")\n",
    "print(1-np.sum(y_test  - pred(w,b,X_test))/len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Assignment.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
